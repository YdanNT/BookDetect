# # -*- coding: utf-8 -*-
# """
# ================================================================================
# ðŸ“š BOOK DETECTOR - Application Streamlit
# ================================================================================
# DÃ©tection automatique de livres sur Ã©tagÃ¨re avec OCR intelligent.
# """

# import os

# # ================== FIX PYTORCH 2.6+ ==================
# # Correction pour le chargement des modÃ¨les YOLO avec PyTorch 2.6+
# try:
#     import torch
#     # Monkey patch pour forcer weights_only=False
#     _original_torch_load = torch.load
    
#     def _patched_torch_load(*args, **kwargs):
#         if 'weights_only' not in kwargs:
#             kwargs['weights_only'] = False
#         return _original_torch_load(*args, **kwargs)
    
#     torch.load = _patched_torch_load
# except Exception:
#     pass

# import streamlit as st
# import math
# import json
# import base64
# import time
# from typing import List, Dict, Any, Optional
# import numpy as np
# import cv2
# import pandas as pd
# import supervision as sv
# from ultralytics import YOLO
# import httpx
# import certifi
# from openai import OpenAI


# # ================== CONFIGURATION API ==================
# # ClÃ© API Scaleway configurÃ©e directement (ne pas partager publiquement)
# os.environ["SCW_SECRET_KEY"] = "ae1d12c9-9fd6-434b-aeba-286e9b9702fa"
# SCW_API_KEY = "ae1d12c9-9fd6-434b-aeba-286e9b9702fa"
# SCW_BASE_URL = "https://api.scaleway.ai/v1"

# # Chemin du modÃ¨le YOLO
# MODEL_PATH = "models/best.pt"


# # ================== CONFIGURATION PAGE ==================
# st.set_page_config(
#     page_title="ðŸ“š Book Detector",
#     page_icon="ðŸ“š",
#     layout="wide",
#     initial_sidebar_state="expanded"
# )

# # CSS Custom
# st.markdown("""
# <style>
#     .stApp {
#         background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
#     }
#     h1 {
#         color: white;
#         text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
#     }
# </style>
# """, unsafe_allow_html=True)


# # ================== CACHE MODÃˆLE ==================
# @st.cache_resource
# def load_yolo_model(model_path: str):
#     """Charge le modÃ¨le YOLO (mis en cache)."""
#     try:
#         if not os.path.exists(model_path):
#             return None, f"Fichier modÃ¨le introuvable : {model_path}"
        
#         # Configuration pour PyTorch 2.6+ : autoriser le chargement de modÃ¨les personnalisÃ©s
#         import torch
        
#         # Ajouter les classes Ultralytics aux globaux sÃ»rs
#         try:
#             from ultralytics.nn.tasks import OBBModel, DetectionModel
#             torch.serialization.add_safe_globals([OBBModel, DetectionModel])
#         except:
#             pass
        
#         # Charger le modÃ¨le avec weights_only=False pour les modÃ¨les personnalisÃ©s
#         model = YOLO(model_path)
#         return model, None
#     except Exception as e:
#         return None, str(e)


# # ================== FONCTIONS GÃ‰OMÃ‰TRIE ==================
# def order_quad_points(pts: np.ndarray) -> np.ndarray:
#     """Ordonne 4 points en [TL, TR, BR, BL]."""
#     pts = np.asarray(pts, dtype=np.float32)
#     s = pts.sum(axis=1)
#     d = np.diff(pts, axis=1).ravel()
    
#     tl = pts[np.argmin(s)]
#     br = pts[np.argmax(s)]
#     tr = pts[np.argmin(d)]
#     bl = pts[np.argmax(d)]
    
#     quad = np.array([tl, tr, br, bl], dtype=np.float32)
    
#     v1 = quad[1] - quad[0]
#     v2 = quad[2] - quad[1]
#     if np.cross(v1, v2) < 0:
#         quad = np.array([tl, bl, br, tr], dtype=np.float32)
    
#     return quad


# def obb_to_corners(cx: float, cy: float, w: float, h: float, angle_deg: float) -> np.ndarray:
#     """Convertit OBB en 4 coins."""
#     angle_rad = math.radians(angle_deg)
#     cos_a = math.cos(angle_rad)
#     sin_a = math.sin(angle_rad)
    
#     dx, dy = w / 2.0, h / 2.0
    
#     local_corners = np.array([
#         [-dx, -dy], [dx, -dy], [dx, dy], [-dx, dy]
#     ], dtype=np.float32)
    
#     rotation_matrix = np.array([[cos_a, -sin_a], [sin_a, cos_a]], dtype=np.float32)
#     rotated = local_corners @ rotation_matrix.T
#     rotated[:, 0] += cx
#     rotated[:, 1] += cy
    
#     return order_quad_points(rotated)


# def extract_crop(image_bgr: np.ndarray, quad: np.ndarray, pad_ratio: float = 0.03, min_side: int = 20):
#     """Extrait un crop depuis un quadrilatÃ¨re."""
#     tl, tr, br, bl = quad
    
#     width_top = np.linalg.norm(tr - tl)
#     width_bottom = np.linalg.norm(br - bl)
#     out_width = int(max(1, round(max(width_top, width_bottom))))
    
#     height_right = np.linalg.norm(tr - br)
#     height_left = np.linalg.norm(tl - bl)
#     out_height = int(max(1, round(max(height_right, height_left))))
    
#     if out_width < min_side or out_height < min_side:
#         return None
    
#     pad_w = int(round(out_width * pad_ratio))
#     pad_h = int(round(out_height * pad_ratio))
#     out_width_padded = out_width + 2 * pad_w
#     out_height_padded = out_height + 2 * pad_h
    
#     dst_points = np.array([
#         [pad_w, pad_h],
#         [pad_w + out_width - 1, pad_h],
#         [pad_w + out_width - 1, pad_h + out_height - 1],
#         [pad_w, pad_h + out_height - 1]
#     ], dtype=np.float32)
    
#     M = cv2.getPerspectiveTransform(quad.astype(np.float32), dst_points)
    
#     crop = cv2.warpPerspective(
#         image_bgr, M,
#         (out_width_padded, out_height_padded),
#         flags=cv2.INTER_CUBIC,
#         borderMode=cv2.BORDER_CONSTANT,
#         borderValue=(255, 255, 255)
#     )
    
#     return crop


# # ================== OCR ==================
# def create_ocr_client(api_key: str, base_url: str):
#     """CrÃ©e client OCR Scaleway."""
#     if not api_key:
#         return None
    
#     try:
#         http_client = httpx.Client(
#             timeout=60.0,
#             verify=certifi.where(),
#             http2=False,
#             limits=httpx.Limits(max_connections=5)
#         )
        
#         return OpenAI(base_url=base_url, api_key=api_key, http_client=http_client)
#     except Exception as e:
#         st.error(f"Erreur crÃ©ation client OCR : {e}")
#         return None


# def encode_crop_to_base64(crop: np.ndarray, quality: int = 85) -> str:
#     """Encode crop en base64."""
#     if len(crop.shape) == 3:
#         crop = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)
    
#     if len(crop.shape) == 2:
#         crop = cv2.cvtColor(crop, cv2.COLOR_GRAY2BGR)
    
#     h, w = crop.shape[:2]
#     if max(h, w) > 1000:
#         scale = 1000 / max(h, w)
#         crop = cv2.resize(crop, (int(w*scale), int(h*scale)), interpolation=cv2.INTER_AREA)
    
#     encode_params = [int(cv2.IMWRITE_JPEG_QUALITY), quality, int(cv2.IMWRITE_JPEG_OPTIMIZE), 1]
#     success, buffer = cv2.imencode(".jpg", crop, encode_params)
    
#     if not success:
#         raise RuntimeError("Ã‰chec encodage JPEG")
    
#     b64 = base64.b64encode(buffer.tobytes()).decode("utf-8")
#     return f"data:image/jpeg;base64,{b64}"


# PROMPT_OCR = """Tu es un expert en OCR de tranches de livres franÃ§ais.

# CONTEXTE: Chaque image montre UNE tranche de livre (texte vertical ou horizontal).

# INSTRUCTIONS: Pour CHAQUE image, extrais:
# 1. **lines** (array): TOUTES les lignes visibles, de HAUT en BAS
# 2. **title** (string): Le titre principal
# 3. **author** (string): L'auteur complet (PrÃ©nom NOM)
# 4. **publisher** (string): L'Ã©diteur si visible

# EXEMPLES:

# Exemple 1: "LA TABLE | DES LOUPS | Adam Rapp | RIVAGES"
# â†’ {{"lines": ["LA TABLE", "DES LOUPS", "Adam Rapp", "RIVAGES"], "title": "La Table des Loups", "author": "Adam Rapp", "publisher": "RIVAGES"}}

# Exemple 2: Image illisible
# â†’ {{"lines": [], "title": "", "author": "", "publisher": ""}}

# RÃˆGLES: N'invente RIEN. Garde les accents. Si incertain â†’ ""

# FORMAT: {{"results": [{{"lines": [...], "title": "...", "author": "...", "publisher": "..."}}, ...]}}

# Traite les {num_images} images."""


# def process_ocr_batch(crops: List[np.ndarray], client, max_tokens: int = 1800, max_retries: int = 4):
#     """Traite un batch OCR."""
#     num_crops = len(crops)
    
#     content = [{"type": "text", "text": PROMPT_OCR.format(num_images=num_crops)}]
    
#     for crop in crops:
#         content.append({"type": "image_url", "image_url": {"url": encode_crop_to_base64(crop)}})
    
#     for attempt in range(max_retries + 1):
#         try:
#             response = client.chat.completions.create(
#                 model="pixtral-12b-2409",
#                 response_format={"type": "json_object"},
#                 temperature=0.0,
#                 max_tokens=max_tokens,
#                 messages=[{"role": "user", "content": content}]
#             )
            
#             data = json.loads(response.choices[0].message.content or "{}")
#             results = data.get("results", [])
            
#             normalized = []
#             for item in results:
#                 normalized.append({
#                     "title": (item.get("title") or "").strip(),
#                     "author": (item.get("author") or "").strip(),
#                     "publisher": (item.get("publisher") or "").strip(),
#                     "lines": [l.strip() for l in item.get("lines", []) if l]
#                 })
            
#             while len(normalized) < num_crops:
#                 normalized.append({"title": "", "author": "", "publisher": "", "lines": []})
            
#             return normalized[:num_crops]
        
#         except Exception as e:
#             if "429" in str(e).lower() and attempt < max_retries:
#                 time.sleep(2.0 * (2 ** attempt))
#                 continue
#             st.warning(f"Erreur OCR (tentative {attempt+1}/{max_retries+1}) : {str(e)}")
#             break
    
#     return [{"title": "", "author": "", "publisher": "", "lines": []} for _ in crops]


# # ================== INTERFACE PRINCIPALE ==================
# def main():
#     """Interface principale Streamlit."""
    
#     # Header
#     col1, col2, col3 = st.columns([1, 2, 1])
#     with col2:
#         st.title("ðŸ“š Book Detector")
#         st.markdown("*DÃ©tection automatique de livres assistÃ©e par IA*")
    
#     # Sidebar
#     with st.sidebar:
#         st.header("âš™ï¸ Configuration")
        
#         st.subheader("ðŸŽ¯ DÃ©tection YOLO")
#         st.info(f"ðŸ“ ModÃ¨le : `{MODEL_PATH}`")
        
#         # VÃ©rifier l'existence du modÃ¨le
#         if not os.path.exists(MODEL_PATH):
#             st.error(f"âŒ Fichier modÃ¨le introuvable !\n\nChemin attendu : `{os.path.abspath(MODEL_PATH)}`")
#             st.info("ðŸ’¡ Assurez-vous que le fichier `best.pt` est dans le mÃªme dossier que ce script.")
        
#         conf_threshold = st.slider("Seuil de confiance", 0.1, 0.95, 0.50, 0.05)
#         iou_threshold = st.slider("Seuil IoU (NMS)", 0.1, 0.95, 0.50, 0.05)
        
#         st.divider()
        
#         st.subheader("ðŸ“ OCR Scaleway")
#         ocr_enabled = st.checkbox("Activer l'OCR", value=True)
        
#         if ocr_enabled:
#             st.success("ðŸ”‘ ClÃ© API configurÃ©e")
#             batch_size = st.slider("Taille batches", 1, 10, 6)
#             max_tokens = st.slider("Tokens max", 500, 3000, 1800, 100)
#         else:
#             batch_size = 6
#             max_tokens = 1800
        
#         st.divider()
        
#         st.subheader("ðŸ”§ Options")
#         sort_left_to_right = st.radio("Ordre de tri", [True, False], format_func=lambda x: "Gauche â†’ Droite" if x else "Droite â†’ Gauche", index=0)
#         pad_ratio = st.slider("Padding (%)", 0, 15, 3) / 100
    
#     # Upload
#     st.header("ðŸ“¤ Upload d'image")
#     uploaded_file = st.file_uploader("Choisissez une photo de votre Ã©tagÃ¨re", type=["jpg", "jpeg", "png"])
    
#     if uploaded_file is not None:
#         # Chargement
#         with st.spinner("â³ Chargement de l'image..."):
#             file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
#             image_bgr = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)
            
#             if image_bgr is None:
#                 st.error("âŒ Impossible de charger l'image")
#                 return
            
#             H, W = image_bgr.shape[:2]
#             st.success(f"âœ… Image chargÃ©e : {W}x{H}px")
        
#         # ModÃ¨le
#         with st.spinner("ðŸ¤– Chargement du modÃ¨le YOLO..."):
#             model, error = load_yolo_model(MODEL_PATH)
            
#             if model is None:
#                 st.error(f"âŒ Erreur de chargement du modÃ¨le")
#                 st.error(error)
#                 st.info(f"VÃ©rifiez que le fichier `{MODEL_PATH}` existe et est un modÃ¨le YOLO valide.")
#                 return
            
#             st.success("âœ… ModÃ¨le chargÃ© avec succÃ¨s")
        
#         # DÃ©tection
#         progress_bar = st.progress(0)
        
#         with st.spinner("ðŸ” DÃ©tection des livres en cours..."):
#             progress_bar.progress(20)
            
#             try:
#                 results = model.predict(image_bgr, conf=conf_threshold, iou=iou_threshold, verbose=False)
#                 detections = sv.Detections.from_ultralytics(results[0])
#             except Exception as e:
#                 st.error(f"âŒ Erreur lors de la dÃ©tection : {str(e)}")
#                 progress_bar.empty()
#                 return
            
#             progress_bar.progress(40)
        
#         if len(detections) == 0:
#             st.warning("âš ï¸ Aucun livre dÃ©tectÃ©. Essayez d'ajuster les seuils de confiance.")
#             progress_bar.empty()
#             return
        
#         # Annotation
#         box_annotator = sv.OrientedBoxAnnotator(thickness=5)
#         image_annotated = box_annotator.annotate(scene=image_bgr.copy(), detections=detections)
        
#         label_annotator = sv.LabelAnnotator(text_scale=1, text_thickness=5)
#         labels = [f"{conf:.2f}" for conf in detections.confidence]
#         image_annotated = label_annotator.annotate(scene=image_annotated, detections=detections, labels=labels)
        
#         # Extraction crops
#         progress_bar.progress(60)
        
#         if "obb" in detections.data:
#             data_type = "obb"
#             data_array = np.asarray(detections.data["obb"], dtype=float)
#         elif "xyxyxyxy" in detections.data:
#             data_type = "xyxyxyxy"
#             data_array = np.asarray(detections.data["xyxyxyxy"], dtype=float)
#         else:
#             st.error("âŒ Format de dÃ©tection inconnu")
#             progress_bar.empty()
#             return
        
#         conf_array = np.asarray(detections.confidence, dtype=float)
#         keep_mask = conf_array >= conf_threshold
#         indices_keep = np.arange(len(conf_array))[keep_mask]
        
#         crops_raw = []
        
#         for j, original_idx in enumerate(indices_keep):
#             if data_type == "obb":
#                 cx, cy, w, h, angle = data_array[original_idx]
#                 if max(abs(cx), abs(cy), abs(w), abs(h)) <= 1.2:
#                     cx *= W; cy *= H; w *= W; h *= H
#                 quad = obb_to_corners(cx, cy, w, h, angle)
#             else:
#                 pts = data_array[original_idx]
#                 if pts.ndim == 1 and len(pts) == 8:
#                     pts = pts.reshape(4, 2)
#                 if np.max(np.abs(pts)) <= 1.2:
#                     pts[:, 0] *= W; pts[:, 1] *= H
#                 quad = order_quad_points(pts)
            
#             quad[:, 0] = np.clip(quad[:, 0], 0, W - 1)
#             quad[:, 1] = np.clip(quad[:, 1], 0, H - 1)
            
#             crop = extract_crop(image_bgr, quad, pad_ratio=pad_ratio)
            
#             if crop is None:
#                 continue
            
#             center_x = float(quad[:, 0].mean())
            
#             crops_raw.append({
#                 "crop": crop,
#                 "quad": quad,
#                 "center_x": center_x,
#                 "confidence": conf_array[original_idx]
#             })
        
#         # Tri
#         crops_raw.sort(key=lambda x: x["center_x"], reverse=not sort_left_to_right)
        
#         # NumÃ©ros
#         for idx, item in enumerate(crops_raw, start=1):
#             quad = item["quad"]
#             center = quad.mean(axis=0).astype(int)
            
#             cv2.circle(image_annotated, tuple(center), 30, (0, 255, 0), -1)
#             cv2.circle(image_annotated, tuple(center), 30, (0, 0, 0), 3)
            
#             text = str(idx)
#             font = cv2.FONT_HERSHEY_SIMPLEX
            
#             text_size = cv2.getTextSize(text, font, 1.5, 4)[0]
#             text_x = center[0] - text_size[0] // 2
#             text_y = center[1] + text_size[1] // 2
            
#             cv2.putText(image_annotated, text, (text_x, text_y), font, 1.5, (255, 255, 255), 4, cv2.LINE_AA)
        
#         progress_bar.progress(80)
        
#         # OCR
#         ocr_results = []
        
#         if ocr_enabled and SCW_API_KEY:
#             with st.spinner("ðŸ”¤ Extraction du texte avec OCR..."):
#                 ocr_client = create_ocr_client(SCW_API_KEY, SCW_BASE_URL)
                
#                 if ocr_client:
#                     crops = [item["crop"] for item in crops_raw]
                    
#                     for i in range(0, len(crops), batch_size):
#                         batch = crops[i:i+batch_size]
#                         results = process_ocr_batch(batch, ocr_client, max_tokens=max_tokens)
#                         ocr_results.extend(results)
                        
#                         if i + batch_size < len(crops):
#                             time.sleep(2.5)
#                 else:
#                     st.warning("âš ï¸ Impossible de crÃ©er le client OCR")
#                     ocr_results = [{"title": "", "author": "", "publisher": "", "lines": []} for _ in crops_raw]
#         else:
#             ocr_results = [{"title": "", "author": "", "publisher": "", "lines": []} for _ in crops_raw]
        
#         progress_bar.progress(100)
#         time.sleep(0.3)
#         progress_bar.empty()
        
#         # RÃ©sultats
#         st.success(f"ðŸŽ‰ {len(crops_raw)} livre(s) dÃ©tectÃ©(s) !")
        
#         # MÃ©triques
#         col1, col2, col3, col4 = st.columns(4)
        
#         with col1:
#             st.metric("ðŸ“š Livres", len(crops_raw))
#         with col2:
#             st.metric("ðŸ“– Titres", sum(1 for r in ocr_results if r.get("title")))
#         with col3:
#             st.metric("âœï¸ Auteurs", sum(1 for r in ocr_results if r.get("author")))
#         with col4:
#             st.metric("ðŸ¢ Ã‰diteurs", sum(1 for r in ocr_results if r.get("publisher")))
        
#         st.divider()
        
#         # Tabs
#         tab1, tab2, tab3, tab4 = st.tabs(["ðŸ“¸ Image annotÃ©e", "ðŸ“š Liste dÃ©taillÃ©e", "ðŸ“Š Tableau", "ðŸ’¾ Export"])
        
#         with tab1:
#             st.subheader("Image avec dÃ©tections")
#             st.image(cv2.cvtColor(image_annotated, cv2.COLOR_BGR2RGB), use_container_width=True)
        
#         with tab2:
#             st.subheader("Liste des livres dÃ©tectÃ©s")
            
#             for idx, (item, ocr_data) in enumerate(zip(crops_raw, ocr_results), start=1):
#                 with st.expander(f"ðŸ“– Livre #{idx} - {ocr_data.get('title') or '(inconnu)'}"):
#                     col_img, col_info = st.columns([1, 2])
                    
#                     with col_img:
#                         st.image(cv2.cvtColor(item["crop"], cv2.COLOR_BGR2RGB))
#                         st.caption(f"Confiance : {item['confidence']:.2%}")
                    
#                     with col_info:
#                         st.markdown(f"**Titre:** {ocr_data.get('title') or '*(inconnu)*'}")
#                         st.markdown(f"**Auteur:** {ocr_data.get('author') or '*(inconnu)*'}")
#                         st.markdown(f"**Ã‰diteur:** {ocr_data.get('publisher') or '*(inconnu)*'}")
                        
#                         if ocr_data.get('lines'):
#                             st.markdown("**Lignes dÃ©tectÃ©es:**")
#                             for line in ocr_data['lines'][:10]:
#                                 st.text(f"  â€¢ {line}")
        
#         with tab3:
#             st.subheader("Vue tableau")
#             df_data = []
#             for idx, (item, ocr_data) in enumerate(zip(crops_raw, ocr_results), start=1):
#                 df_data.append({
#                     "#": idx,
#                     "Titre": ocr_data.get('title') or '(inconnu)',
#                     "Auteur": ocr_data.get('author') or '(inconnu)',
#                     "Ã‰diteur": ocr_data.get('publisher') or '(inconnu)',
#                     "Confiance": f"{item['confidence']:.2%}"
#                 })
            
#             df = pd.DataFrame(df_data)
#             st.dataframe(df, use_container_width=True, hide_index=True)
        
#         with tab4:
#             st.subheader("Exporter les rÃ©sultats")
#             col_csv, col_json = st.columns(2)
            
#             with col_csv:
#                 csv = df.to_csv(index=False).encode('utf-8')
#                 st.download_button("ðŸ“¥ TÃ©lÃ©charger CSV", csv, "livres.csv", "text/csv", key="csv_download")
            
#             with col_json:
#                 json_data = json.dumps([
#                     {
#                         "index": idx,
#                         "titre": ocr_data.get('title'),
#                         "auteur": ocr_data.get('author'),
#                         "editeur": ocr_data.get('publisher'),
#                         "confiance": float(item['confidence'])
#                     }
#                     for idx, (item, ocr_data) in enumerate(zip(crops_raw, ocr_results), start=1)
#                 ], ensure_ascii=False, indent=2)
                
#                 st.download_button("ðŸ“¥ TÃ©lÃ©charger JSON", json_data.encode('utf-8'), "livres.json", "application/json", key="json_download")


# if __name__ == "__main__":
#     main()
    
#     # Footer
#     st.divider()
#     col1, col2 = st.columns(2)
    
#     with col1:
#         st.markdown("ðŸ“š **Book Detector v1.0**")
#     with col2:
#         st.markdown("ðŸš€ *Powered by YOLO + Scaleway OCR*")

# -*- coding: utf-8 -*-
"""
================================================================================
ðŸ“š BOOK DETECTOR - Application Streamlit
================================================================================
DÃ©tection automatique de livres sur Ã©tagÃ¨re avec OCR intelligent.
"""

import os

# ================== FIX PYTORCH 2.6+ ==================
# Correction pour le chargement des modÃ¨les YOLO avec PyTorch 2.6+
try:
    import torch
    # Monkey patch pour forcer weights_only=False
    _original_torch_load = torch.load
    
    def _patched_torch_load(*args, **kwargs):
        if 'weights_only' not in kwargs:
            kwargs['weights_only'] = False
        return _original_torch_load(*args, **kwargs)
    
    torch.load = _patched_torch_load
except Exception:
    pass

import streamlit as st
import math
import json
import base64
import time
from typing import List, Dict, Any, Optional
import numpy as np
import cv2
import pandas as pd
import supervision as sv
from ultralytics import YOLO
import httpx
import certifi
from openai import OpenAI
from fuzzywuzzy import fuzz


# ================== CONFIGURATION API ==================
# ClÃ© API Scaleway configurÃ©e directement (ne pas partager publiquement)
os.environ["SCW_SECRET_KEY"] = "ae1d12c9-9fd6-434b-aeba-286e9b9702fa"
SCW_API_KEY = "ae1d12c9-9fd6-434b-aeba-286e9b9702fa"
SCW_BASE_URL = "https://api.scaleway.ai/v1"

# Chemin du modÃ¨le YOLO
MODEL_PATH = "models/epoch_100_yolo12x-obb_new.pt"

# ================== AJOUT : Fichier stock ==================
STOCK_FILE = "Stock_20251030.xls"


# ================== CONFIGURATION PAGE ==================
st.set_page_config(
    page_title="ðŸ“š Book Detector",
    page_icon="ðŸ“š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS Custom
st.markdown("""
<style>
    .stApp {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    }
    h1 {
        color: white;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
    }
    .match-card {
        padding: 10px;
        border-radius: 8px;
        margin: 8px 0;
    }
    .match-found { background: #d4edda; border-left: 4px solid #28a745; }
    .match-uncertain { background: #fff3cd; border-left: 4px solid #ffc107; }
    .match-notfound { background: #f8d7da; border-left: 4px solid #dc3545; }
</style>
""", unsafe_allow_html=True)


# ================== CACHE MODÃˆLE ==================
@st.cache_resource
def load_yolo_model(model_path: str):
    """Charge le modÃ¨le YOLO (mis en cache)."""
    try:
        if not os.path.exists(model_path):
            return None, f"Fichier modÃ¨le introuvable : {model_path}"
        
        # Configuration pour PyTorch 2.6+ : autoriser le chargement de modÃ¨les personnalisÃ©s
        import torch
        
        # Ajouter les classes Ultralytics aux globaux sÃ»rs
        try:
            from ultralytics.nn.tasks import OBBModel, DetectionModel
            torch.serialization.add_safe_globals([OBBModel, DetectionModel])
        except:
            pass
        
        # Charger le modÃ¨le avec weights_only=False pour les modÃ¨les personnalisÃ©s
        model = YOLO(model_path)
        return model, None
    except Exception as e:
        return None, str(e)


# ================== AJOUT : Cache stock ==================
@st.cache_data
def load_stock(file_path: str) -> Optional[pd.DataFrame]:
    """Charge le fichier stock Excel."""
    try:
        if not os.path.exists(file_path):
            return None
        df = pd.read_excel(file_path, engine='xlrd')
        # Normaliser les colonnes
        df['Titre'] = df['Titre'].astype(str).str.strip().str.upper()
        df['Auteur'] = df['Auteur'].astype(str).str.strip().str.upper()
        df['Editeur'] = df['Editeur'].astype(str).str.strip().str.upper()
        return df
    except Exception as e:
        st.error(f"Erreur chargement stock : {e}")
        return None


# ================== AJOUT : Matching fonctions ==================
def normalize_text(text: str) -> str:
    """Normalise le texte pour le matching."""
    if not text or text == "nan":
        return ""
    text = str(text).upper().strip()
    # Supprimer accents basiques
    replacements = {'Ã€':'A','Ã':'A','Ã‚':'A','Ãƒ':'A','Ã„':'A','Ãˆ':'E','Ã‰':'E','ÃŠ':'E','Ã‹':'E',
                   'ÃŒ':'I','Ã':'I','ÃŽ':'I','Ã':'I','Ã’':'O','Ã“':'O','Ã”':'O','Ã•':'O','Ã–':'O',
                   'Ã™':'U','Ãš':'U','Ã›':'U','Ãœ':'U','Ã‡':'C','Å’':'OE','Ã†':'AE'}
    for old, new in replacements.items():
        text = text.replace(old, new)
    # Garder seulement alphanum et espaces
    text = ''.join(c if c.isalnum() or c.isspace() else ' ' for c in text)
    return ' '.join(text.split())


def match_book(ocr_title: str, ocr_author: str, ocr_publisher: str, 
               stock_df: pd.DataFrame, threshold: int = 60):
    """Trouve la meilleure correspondance dans le stock."""
    if stock_df is None or stock_df.empty:
        return None, 0
    
    ocr_title = normalize_text(ocr_title)
    ocr_author = normalize_text(ocr_author)
    ocr_publisher = normalize_text(ocr_publisher)
    
    if not ocr_title and not ocr_author:
        return None, 0
    
    best_score = 0
    best_match = None
    
    for _, row in stock_df.iterrows():
        stock_title = normalize_text(row['Titre'])
        stock_author = normalize_text(row['Auteur'])
        stock_publisher = normalize_text(row['Editeur'])
        
        # Score pondÃ©rÃ© : Titre 60%, Auteur 30%, Ã‰diteur 10%
        title_score = 0
        if ocr_title and stock_title:
            title_score = max(
                fuzz.ratio(ocr_title, stock_title),
                fuzz.partial_ratio(ocr_title, stock_title),
                fuzz.token_sort_ratio(ocr_title, stock_title)
            ) * 0.6
        
        author_score = 0
        if ocr_author and stock_author:
            author_score = max(
                fuzz.ratio(ocr_author, stock_author),
                fuzz.token_set_ratio(ocr_author, stock_author)
            ) * 0.3
        
        publisher_score = 0
        if ocr_publisher and stock_publisher:
            publisher_score = fuzz.partial_ratio(ocr_publisher, stock_publisher) * 0.1
        
        score = title_score + author_score + publisher_score
        
        if score > best_score:
            best_score = score
            best_match = row
    
    if best_score >= threshold:
        return best_match, best_score
    return None, best_score


# ================== FONCTIONS GÃ‰OMÃ‰TRIE ==================
def order_quad_points(pts: np.ndarray) -> np.ndarray:
    """Ordonne 4 points en [TL, TR, BR, BL]."""
    pts = np.asarray(pts, dtype=np.float32)
    s = pts.sum(axis=1)
    d = np.diff(pts, axis=1).ravel()
    
    tl = pts[np.argmin(s)]
    br = pts[np.argmax(s)]
    tr = pts[np.argmin(d)]
    bl = pts[np.argmax(d)]
    
    quad = np.array([tl, tr, br, bl], dtype=np.float32)
    
    v1 = quad[1] - quad[0]
    v2 = quad[2] - quad[1]
    if np.cross(v1, v2) < 0:
        quad = np.array([tl, bl, br, tr], dtype=np.float32)
    
    return quad


def obb_to_corners(cx: float, cy: float, w: float, h: float, angle_deg: float) -> np.ndarray:
    """Convertit OBB en 4 coins."""
    angle_rad = math.radians(angle_deg)
    cos_a = math.cos(angle_rad)
    sin_a = math.sin(angle_rad)
    
    dx, dy = w / 2.0, h / 2.0
    
    local_corners = np.array([
        [-dx, -dy], [dx, -dy], [dx, dy], [-dx, dy]
    ], dtype=np.float32)
    
    rotation_matrix = np.array([[cos_a, -sin_a], [sin_a, cos_a]], dtype=np.float32)
    rotated = local_corners @ rotation_matrix.T
    rotated[:, 0] += cx
    rotated[:, 1] += cy
    
    return order_quad_points(rotated)


def extract_crop(image_bgr: np.ndarray, quad: np.ndarray, pad_ratio: float = 0.03, min_side: int = 20):
    """Extrait un crop depuis un quadrilatÃ¨re."""
    tl, tr, br, bl = quad
    
    width_top = np.linalg.norm(tr - tl)
    width_bottom = np.linalg.norm(br - bl)
    out_width = int(max(1, round(max(width_top, width_bottom))))
    
    height_right = np.linalg.norm(tr - br)
    height_left = np.linalg.norm(tl - bl)
    out_height = int(max(1, round(max(height_right, height_left))))
    
    if out_width < min_side or out_height < min_side:
        return None
    
    pad_w = int(round(out_width * pad_ratio))
    pad_h = int(round(out_height * pad_ratio))
    out_width_padded = out_width + 2 * pad_w
    out_height_padded = out_height + 2 * pad_h
    
    dst_points = np.array([
        [pad_w, pad_h],
        [pad_w + out_width - 1, pad_h],
        [pad_w + out_width - 1, pad_h + out_height - 1],
        [pad_w, pad_h + out_height - 1]
    ], dtype=np.float32)
    
    M = cv2.getPerspectiveTransform(quad.astype(np.float32), dst_points)
    
    crop = cv2.warpPerspective(
        image_bgr, M,
        (out_width_padded, out_height_padded),
        flags=cv2.INTER_CUBIC,
        borderMode=cv2.BORDER_CONSTANT,
        borderValue=(255, 255, 255)
    )
    
    return crop


# ================== OCR ==================
def create_ocr_client(api_key: str, base_url: str):
    """CrÃ©e client OCR Scaleway."""
    if not api_key:
        return None
    
    try:
        http_client = httpx.Client(
            timeout=60.0,
            verify=certifi.where(),
            http2=False,
            limits=httpx.Limits(max_connections=5)
        )
        
        return OpenAI(base_url=base_url, api_key=api_key, http_client=http_client)
    except Exception as e:
        st.error(f"Erreur crÃ©ation client OCR : {e}")
        return None


def encode_crop_to_base64(crop: np.ndarray, quality: int = 85) -> str:
    """Encode crop en base64."""
    if len(crop.shape) == 3:
        crop = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)
    
    if len(crop.shape) == 2:
        crop = cv2.cvtColor(crop, cv2.COLOR_GRAY2BGR)
    
    h, w = crop.shape[:2]
    if max(h, w) > 1000:
        scale = 1000 / max(h, w)
        crop = cv2.resize(crop, (int(w*scale), int(h*scale)), interpolation=cv2.INTER_AREA)
    
    encode_params = [int(cv2.IMWRITE_JPEG_QUALITY), quality, int(cv2.IMWRITE_JPEG_OPTIMIZE), 1]
    success, buffer = cv2.imencode(".jpg", crop, encode_params)
    
    if not success:
        raise RuntimeError("Ã‰chec encodage JPEG")
    
    b64 = base64.b64encode(buffer.tobytes()).decode("utf-8")
    return f"data:image/jpeg;base64,{b64}"


PROMPT_OCR = """Tu es un expert en OCR de tranches de livres franÃ§ais.

CONTEXTE: Chaque image montre UNE tranche de livre (texte vertical ou horizontal).

INSTRUCTIONS: Pour CHAQUE image, extrais:
1. **lines** (array): TOUTES les lignes visibles, de HAUT en BAS
2. **title** (string): Le titre principal
3. **author** (string): L'auteur complet (PrÃ©nom NOM)
4. **publisher** (string): L'Ã©diteur si visible

EXEMPLES:

Exemple 1: "LA TABLE | DES LOUPS | Adam Rapp | RIVAGES"
â†’ {{"lines": ["LA TABLE", "DES LOUPS", "Adam Rapp", "RIVAGES"], "title": "La Table des Loups", "author": "Adam Rapp", "publisher": "RIVAGES"}}

Exemple 2: Image illisible
â†’ {{"lines": [], "title": "", "author": "", "publisher": ""}}

RÃˆGLES: N'invente RIEN. Garde les accents. Si incertain â†’ ""

FORMAT: {{"results": [{{"lines": [...], "title": "...", "author": "...", "publisher": "..."}}, ...]}}

Traite les {num_images} images."""


def process_ocr_batch(crops: List[np.ndarray], client, max_tokens: int = 1800, max_retries: int = 4):
    """Traite un batch OCR."""
    num_crops = len(crops)
    
    content = [{"type": "text", "text": PROMPT_OCR.format(num_images=num_crops)}]
    
    for crop in crops:
        content.append({"type": "image_url", "image_url": {"url": encode_crop_to_base64(crop)}})
    
    for attempt in range(max_retries + 1):
        try:
            response = client.chat.completions.create(
                model="pixtral-12b-2409",
                response_format={"type": "json_object"},
                temperature=0.0,
                max_tokens=max_tokens,
                messages=[{"role": "user", "content": content}]
            )
            
            data = json.loads(response.choices[0].message.content or "{}")
            results = data.get("results", [])
            
            normalized = []
            for item in results:
                normalized.append({
                    "title": (item.get("title") or "").strip(),
                    "author": (item.get("author") or "").strip(),
                    "publisher": (item.get("publisher") or "").strip(),
                    "lines": [l.strip() for l in item.get("lines", []) if l]
                })
            
            while len(normalized) < num_crops:
                normalized.append({"title": "", "author": "", "publisher": "", "lines": []})
            
            return normalized[:num_crops]
        
        except Exception as e:
            if "429" in str(e).lower() and attempt < max_retries:
                time.sleep(2.0 * (2 ** attempt))
                continue
            st.warning(f"Erreur OCR (tentative {attempt+1}/{max_retries+1}) : {str(e)}")
            break
    
    return [{"title": "", "author": "", "publisher": "", "lines": []} for _ in crops]


# ================== INTERFACE PRINCIPALE ==================
def main():
    """Interface principale Streamlit."""
    
    # Header
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        st.title("ðŸ“š Book Detector")
        st.markdown("*DÃ©tection automatique de livres assistÃ©e par IA*")
    
    # ================== AJOUT : Chargement stock ==================
    stock_df = load_stock(STOCK_FILE)
    if stock_df is not None:
        st.success(f"âœ… Stock chargÃ© : {len(stock_df):,} livres")
    else:
        st.warning("âš ï¸ Stock non disponible - Matching dÃ©sactivÃ©")
    
    # Sidebar
    with st.sidebar:
        st.header("âš™ï¸ Configuration")
        
        st.subheader("ðŸŽ¯ DÃ©tection YOLO")
        st.info(f"ðŸ“ ModÃ¨le : `{MODEL_PATH}`")
        
        # VÃ©rifier l'existence du modÃ¨le
        if not os.path.exists(MODEL_PATH):
            st.error(f"âŒ Fichier modÃ¨le introuvable !\n\nChemin attendu : `{os.path.abspath(MODEL_PATH)}`")
            st.info("ðŸ’¡ Assurez-vous que le fichier `best.pt` est dans le mÃªme dossier que ce script.")
        
        conf_threshold = st.slider("Seuil de confiance", 0.1, 0.95, 0.50, 0.05)
        iou_threshold = st.slider("Seuil IoU (NMS)", 0.1, 0.95, 0.50, 0.05)
        
        st.divider()
        
        st.subheader("ðŸ“ OCR Scaleway")
        ocr_enabled = st.checkbox("Activer l'OCR", value=True)
        
        if ocr_enabled:
            st.success("ðŸ”‘ ClÃ© API configurÃ©e")
            batch_size = st.slider("Taille batches", 1, 10, 6)
            max_tokens = st.slider("Tokens max", 500, 3000, 1800, 100)
        else:
            batch_size = 6
            max_tokens = 1800
        
        st.divider()
        
        # ================== AJOUT : ParamÃ¨tres matching ==================
        if stock_df is not None:
            st.subheader("ðŸ”Ž Matching Stock")
            match_threshold = st.slider("Seuil matching (%)", 40, 90, 60, 5)
            st.caption(f"âœ… â‰¥{match_threshold}% : TrouvÃ©")
            st.caption(f"âš ï¸ 40-{match_threshold-1}% : Incertain")
            st.caption(f"âŒ <40% : Non trouvÃ©")
            st.divider()
        else:
            match_threshold = 60
        
        st.subheader("ðŸ”§ Options")
        sort_left_to_right = st.radio("Ordre de tri", [True, False], format_func=lambda x: "Gauche â†’ Droite" if x else "Droite â†’ Gauche", index=0)
        pad_ratio = st.slider("Padding (%)", 0, 15, 3) / 100
    
    # Upload
    st.header("ðŸ“¤ Upload d'image")
    uploaded_file = st.file_uploader("Choisissez une photo de votre Ã©tagÃ¨re", type=["jpg", "jpeg", "png"])
    
    if uploaded_file is not None:
        # Chargement
        with st.spinner("â³ Chargement de l'image..."):
            file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
            image_bgr = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)
            
            if image_bgr is None:
                st.error("âŒ Impossible de charger l'image")
                return
            
            H, W = image_bgr.shape[:2]
            st.success(f"âœ… Image chargÃ©e : {W}x{H}px")
        
        # ModÃ¨le
        with st.spinner("ðŸ¤– Chargement du modÃ¨le YOLO..."):
            model, error = load_yolo_model(MODEL_PATH)
            
            if model is None:
                st.error(f"âŒ Erreur de chargement du modÃ¨le")
                st.error(error)
                st.info(f"VÃ©rifiez que le fichier `{MODEL_PATH}` existe et est un modÃ¨le YOLO valide.")
                return
            
            st.success("âœ… ModÃ¨le chargÃ© avec succÃ¨s")
        
        # DÃ©tection
        progress_bar = st.progress(0)
        
        with st.spinner("ðŸ” DÃ©tection des livres en cours..."):
            progress_bar.progress(20)
            
            try:
                results = model.predict(image_bgr, conf=conf_threshold, iou=iou_threshold, verbose=False)
                detections = sv.Detections.from_ultralytics(results[0])
            except Exception as e:
                st.error(f"âŒ Erreur lors de la dÃ©tection : {str(e)}")
                progress_bar.empty()
                return
            
            progress_bar.progress(40)
        
        if len(detections) == 0:
            st.warning("âš ï¸ Aucun livre dÃ©tectÃ©. Essayez d'ajuster les seuils de confiance.")
            progress_bar.empty()
            return
        
        # Annotation
        box_annotator = sv.OrientedBoxAnnotator(thickness=5)
        image_annotated = box_annotator.annotate(scene=image_bgr.copy(), detections=detections)
        
        label_annotator = sv.LabelAnnotator(text_scale=1, text_thickness=5)
        labels = [f"{conf:.2f}" for conf in detections.confidence]
        image_annotated = label_annotator.annotate(scene=image_annotated, detections=detections, labels=labels)
        
        # Extraction crops
        progress_bar.progress(60)
        
        if "obb" in detections.data:
            data_type = "obb"
            data_array = np.asarray(detections.data["obb"], dtype=float)
        elif "xyxyxyxy" in detections.data:
            data_type = "xyxyxyxy"
            data_array = np.asarray(detections.data["xyxyxyxy"], dtype=float)
        else:
            st.error("âŒ Format de dÃ©tection inconnu")
            progress_bar.empty()
            return
        
        conf_array = np.asarray(detections.confidence, dtype=float)
        keep_mask = conf_array >= conf_threshold
        indices_keep = np.arange(len(conf_array))[keep_mask]
        
        crops_raw = []
        
        for j, original_idx in enumerate(indices_keep):
            if data_type == "obb":
                cx, cy, w, h, angle = data_array[original_idx]
                if max(abs(cx), abs(cy), abs(w), abs(h)) <= 1.2:
                    cx *= W; cy *= H; w *= W; h *= H
                quad = obb_to_corners(cx, cy, w, h, angle)
            else:
                pts = data_array[original_idx]
                if pts.ndim == 1 and len(pts) == 8:
                    pts = pts.reshape(4, 2)
                if np.max(np.abs(pts)) <= 1.2:
                    pts[:, 0] *= W; pts[:, 1] *= H
                quad = order_quad_points(pts)
            
            quad[:, 0] = np.clip(quad[:, 0], 0, W - 1)
            quad[:, 1] = np.clip(quad[:, 1], 0, H - 1)
            
            crop = extract_crop(image_bgr, quad, pad_ratio=pad_ratio)
            
            if crop is None:
                continue
            
            center_x = float(quad[:, 0].mean())
            
            crops_raw.append({
                "crop": crop,
                "quad": quad,
                "center_x": center_x,
                "confidence": conf_array[original_idx]
            })
        
        # Tri
        crops_raw.sort(key=lambda x: x["center_x"], reverse=not sort_left_to_right)
        
        # NumÃ©ros
        for idx, item in enumerate(crops_raw, start=1):
            quad = item["quad"]
            center = quad.mean(axis=0).astype(int)
            
            cv2.circle(image_annotated, tuple(center), 30, (0, 255, 0), -1)
            cv2.circle(image_annotated, tuple(center), 30, (0, 0, 0), 3)
            
            text = str(idx)
            font = cv2.FONT_HERSHEY_SIMPLEX
            
            text_size = cv2.getTextSize(text, font, 1.5, 4)[0]
            text_x = center[0] - text_size[0] // 2
            text_y = center[1] + text_size[1] // 2
            
            cv2.putText(image_annotated, text, (text_x, text_y), font, 1.5, (255, 255, 255), 4, cv2.LINE_AA)
        
        progress_bar.progress(80)
        
        # OCR
        ocr_results = []
        
        if ocr_enabled and SCW_API_KEY:
            with st.spinner("ðŸ”¤ Extraction du texte avec OCR..."):
                ocr_client = create_ocr_client(SCW_API_KEY, SCW_BASE_URL)
                
                if ocr_client:
                    crops = [item["crop"] for item in crops_raw]
                    
                    for i in range(0, len(crops), batch_size):
                        batch = crops[i:i+batch_size]
                        results = process_ocr_batch(batch, ocr_client, max_tokens=max_tokens)
                        ocr_results.extend(results)
                        
                        if i + batch_size < len(crops):
                            time.sleep(2.5)
                else:
                    st.warning("âš ï¸ Impossible de crÃ©er le client OCR")
                    ocr_results = [{"title": "", "author": "", "publisher": "", "lines": []} for _ in crops_raw]
        else:
            ocr_results = [{"title": "", "author": "", "publisher": "", "lines": []} for _ in crops_raw]
        
        progress_bar.progress(100)
        time.sleep(0.3)
        progress_bar.empty()
        
        # RÃ©sultats
        st.success(f"ðŸŽ‰ {len(crops_raw)} livre(s) dÃ©tectÃ©(s) !")
        
        # MÃ©triques
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ðŸ“š Livres", len(crops_raw))
        with col2:
            st.metric("ðŸ“– Titres", sum(1 for r in ocr_results if r.get("title")))
        with col3:
            st.metric("âœï¸ Auteurs", sum(1 for r in ocr_results if r.get("author")))
        with col4:
            st.metric("ðŸ¢ Ã‰diteurs", sum(1 for r in ocr_results if r.get("publisher")))
        
        st.divider()
        
        # ================== TABS (mode original + ajout recherche stock) ==================
        if stock_df is not None:
            tabs = st.tabs(["ðŸ“¸ Image annotÃ©e", "ðŸ“š Liste dÃ©taillÃ©e", "ðŸ“Š Tableau", "ðŸ” Recherche Stock", "ðŸ’¾ Export"])
        else:
            tabs = st.tabs(["ðŸ“¸ Image annotÃ©e", "ðŸ“š Liste dÃ©taillÃ©e", "ðŸ“Š Tableau", "ðŸ’¾ Export"])
        
        with tabs[0]:
            st.subheader("Image avec dÃ©tections")
            st.image(cv2.cvtColor(image_annotated, cv2.COLOR_BGR2RGB), use_container_width=True)
        
        with tabs[1]:
            st.subheader("Liste des livres dÃ©tectÃ©s")
            for idx, (item, ocr_data) in enumerate(zip(crops_raw, ocr_results), start=1):
                with st.expander(f"ðŸ“– Livre #{idx} - {ocr_data.get('title') or '(inconnu)'}"):
                    col_img, col_info = st.columns([1, 2])
                    with col_img:
                        st.image(cv2.cvtColor(item["crop"], cv2.COLOR_BGR2RGB))
                        st.caption(f"Confiance : {item['confidence']:.2%}")
                    with col_info:
                        st.markdown(f"**Titre:** {ocr_data.get('title') or '*(inconnu)*'}")
                        st.markdown(f"**Auteur:** {ocr_data.get('author') or '*(inconnu)*'}")
                        st.markdown(f"**Ã‰diteur:** {ocr_data.get('publisher') or '*(inconnu)*'}")
                        if ocr_data.get('lines'):
                            st.markdown("**Lignes dÃ©tectÃ©es:**")
                            for line in ocr_data['lines'][:10]:
                                st.text(f"  â€¢ {line}")
        
        with tabs[2]:
            st.subheader("Vue tableau")
            df_data = []
            for idx, (item, ocr_data) in enumerate(zip(crops_raw, ocr_results), start=1):
                df_data.append({
                    "#": idx,
                    "Titre": ocr_data.get('title') or '(inconnu)',
                    "Auteur": ocr_data.get('author') or '(inconnu)',
                    "Ã‰diteur": ocr_data.get('publisher') or '(inconnu)',
                    "Confiance": f"{item['confidence']:.2%}"
                })
            df = pd.DataFrame(df_data)
            st.dataframe(df, use_container_width=True, hide_index=True)
        
        # ================== AJOUT : Onglet Recherche Stock ==================
        if stock_df is not None:
            with tabs[3]:
                st.subheader("ðŸ” Recherche dans le stock")
                st.info("Cliquez sur un livre dÃ©tectÃ© pour chercher dans votre stock")
                
                # SÃ©lection du livre
                book_options = [f"#{i+1} - {ocr_results[i].get('title') or '(inconnu)'}" for i in range(len(ocr_results))]
                selected = st.selectbox("SÃ©lectionnez un livre dÃ©tectÃ©", book_options)
                
                if selected:
                    book_idx = int(selected.split('#')[1].split(' -')[0]) - 1
                    ocr_data = ocr_results[book_idx]
                    
                    col1, col2 = st.columns([1, 2])
                    
                    with col1:
                        st.markdown("**ðŸ“– DonnÃ©es OCR**")
                        st.text(f"Titre: {ocr_data.get('title') or '(vide)'}")
                        st.text(f"Auteur: {ocr_data.get('author') or '(vide)'}")
                        st.text(f"Ã‰diteur: {ocr_data.get('publisher') or '(vide)'}")
                        st.image(cv2.cvtColor(crops_raw[book_idx]["crop"], cv2.COLOR_BGR2RGB))
                    
                    with col2:
                        st.markdown("**ðŸ”Ž RÃ©sultats de recherche**")
                        
                        # Recherche
                        match_row, score = match_book(
                            ocr_data.get('title', ''),
                            ocr_data.get('author', ''),
                            ocr_data.get('publisher', ''),
                            stock_df,
                            threshold=0  # Seuil Ã  0 pour afficher mÃªme les mauvais matchs
                        )
                        
                        if score > 0:
                            # Afficher le meilleur match
                            st.markdown(f"**Meilleur match (Score: {score:.0f}%)**")
                            
                            if score >= match_threshold:
                                st.success("âœ… Correspondance trouvÃ©e")
                            elif score >= 40:
                                st.warning("âš ï¸ Correspondance incertaine")
                            else:
                                st.error("âŒ Score trop faible")
                            
                            if match_row is not None:
                                st.markdown(f"**Code:** `{match_row['Code article']}`")
                                st.markdown(f"**Titre:** {match_row['Titre']}")
                                st.markdown(f"**Auteur:** {match_row['Auteur']}")
                                st.markdown(f"**Ã‰diteur:** {match_row['Editeur']}")
                                
                                qty = match_row['QtÃ©']
                                if qty > 5:
                                    st.success(f"ðŸ“¦ En stock : {qty} exemplaires")
                                elif qty > 0:
                                    st.warning(f"ðŸ“¦ Stock faible : {qty} exemplaires")
                                else:
                                    st.error("ðŸ“¦ Rupture de stock")
                                
                                st.caption(f"CatÃ©gorie: {match_row['Nom CatÃ©gorie']}")
                                st.caption(f"Distributeur: {match_row['Nom Distributeur']}")
                        else:
                            st.error("âŒ Aucune correspondance trouvÃ©e")
                            st.caption("L'OCR n'a pas extrait assez d'informations pour effectuer une recherche.")
        
        # Export
        export_tab_idx = 4 if stock_df is not None else 3
        with tabs[export_tab_idx]:
            st.subheader("Exporter les rÃ©sultats")
            col_csv, col_json = st.columns(2)
            
            with col_csv:
                csv = df.to_csv(index=False).encode('utf-8')
                st.download_button("ðŸ“¥ TÃ©lÃ©charger CSV", csv, "livres.csv", "text/csv", key="csv_download")
            
            with col_json:
                json_data = json.dumps([
                    {
                        "index": idx,
                        "titre": ocr_data.get('title'),
                        "auteur": ocr_data.get('author'),
                        "editeur": ocr_data.get('publisher'),
                        "confiance": float(item['confidence'])
                    }
                    for idx, (item, ocr_data) in enumerate(zip(crops_raw, ocr_results), start=1)
                ], ensure_ascii=False, indent=2)
                
                st.download_button("ðŸ“¥ TÃ©lÃ©charger JSON", json_data.encode('utf-8'), "livres.json", "application/json", key="json_download")


if __name__ == "__main__":
    main()
    
    st.divider()
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("ðŸ“š **Book Detector v1.0**")
    with col2:
        st.markdown("ðŸš€ *Powered by YOLO + Scaleway OCR*")